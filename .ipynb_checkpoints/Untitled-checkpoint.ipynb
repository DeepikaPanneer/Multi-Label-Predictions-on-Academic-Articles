{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a9e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before applying dynamic MLSMOTE:\n",
      "Computer Science: 6902\n",
      "Physics: 4787\n",
      "Mathematics: 4468\n",
      "Statistics: 4137\n",
      "Quantitative Biology: 465\n",
      "Quantitative Finance: 204\n",
      "\n",
      "\n",
      "Class distribution after applying dynamic MLSMOTE:\n",
      "Computer Science: 7570\n",
      "Physics: 4801\n",
      "Mathematics: 4575\n",
      "Statistics: 5683\n",
      "Quantitative Biology: 4557\n",
      "Quantitative Finance: 4536\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "train_data['TEXT'] = train_data['TITLE'] + ' ' + train_data['ABSTRACT']\n",
    "\n",
    "X = train_data['TEXT']\n",
    "y = train_data[['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']].values\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Transform the input features\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Helper function to identify minority labels\n",
    "def get_tail_labels(y):\n",
    "    tail_labels = [i for i in range(y.shape[1]) if np.sum(y[:, i]) < (y.shape[0] / 2)]\n",
    "    return tail_labels\n",
    "\n",
    "# class distribution before applying dynamic MLSMOTE\n",
    "print(\"Class distribution before applying dynamic MLSMOTE:\")\n",
    "for i, label in enumerate(['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']):\n",
    "    print(f\"{label}: {np.sum(y_train[:, i])}\")\n",
    "\n",
    "# Dynamic MLSMOTE function\n",
    "def dynamic_MLSMOTE(X, y, target_balance=4500):\n",
    "    n_neighbors = min(5, X.shape[0] - 1)\n",
    "    neigh = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    neigh.fit(X)\n",
    "    tail_labels = get_tail_labels(y)\n",
    "    synthetic_samples = []\n",
    "    synthetic_labels = []\n",
    "\n",
    "    for i in tail_labels:\n",
    "        current_count = np.sum(y[:, i])\n",
    "        n_samples = max(target_balance - current_count, 0)  # Calculate the number of samples to generate\n",
    "        target_indices = np.where(y[:, i] == 1)[0]\n",
    "        \n",
    "        if len(target_indices) >= n_neighbors:\n",
    "            nn = neigh.kneighbors(X[target_indices], return_distance=False)\n",
    "            for _ in range(n_samples):\n",
    "                sample_index = random.choice(range(len(target_indices)))\n",
    "                nn_indices = nn[sample_index, 1:]\n",
    "                chosen_nn = random.choice(nn_indices)\n",
    "                step = np.random.rand()\n",
    "                synthetic_sample = X[target_indices[sample_index]] + step * (X[chosen_nn] - X[target_indices[sample_index]])\n",
    "                synthetic_samples.append(synthetic_sample)\n",
    "                synthetic_label = y[target_indices[sample_index]].copy()\n",
    "                synthetic_labels.append(synthetic_label)\n",
    "    \n",
    "    if len(synthetic_samples) > 0:\n",
    "        X_synthetic = np.vstack(synthetic_samples)\n",
    "        y_synthetic = np.vstack(synthetic_labels)\n",
    "        X_balanced = np.vstack((X, X_synthetic))\n",
    "        y_balanced = np.vstack((y, y_synthetic))\n",
    "        return X_balanced, y_balanced\n",
    "    else:\n",
    "        return X, y\n",
    "\n",
    "# Convert y_train to numpy array for processing\n",
    "y_train_np = y_train\n",
    "\n",
    "# Adjust this target balance\n",
    "target_balance = 4500  \n",
    "X_balanced_wv, y_balanced = dynamic_MLSMOTE(X_train_tfidf, y_train_np, target_balance=target_balance)\n",
    "\n",
    "# class distribution after applying dynamic MLSMOTE\n",
    "print(\"\\n\")\n",
    "print(\"Class distribution after applying dynamic MLSMOTE:\")\n",
    "for i, label in enumerate(['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']):\n",
    "    print(f\"{label}: {np.sum(y_balanced[:, i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62dc02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
